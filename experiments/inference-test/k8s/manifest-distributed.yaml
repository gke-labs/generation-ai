apiVersion: v1
kind: Service
metadata:
  name: inference-test-headless
spec:
  clusterIP: None
  selector:
    app: inference-test
---
apiVersion: batch/v1
kind: Job
metadata:
  name: inference-test
spec:
  completionMode: Indexed
  completions: 2
  parallelism: 2
  template:
    metadata:
      labels:
        app: inference-test
    spec:
      subdomain: inference-test-headless
      containers:
      - name: inference-test
        image: IMAGE_PLACEHOLDER
        resources:
          limits:
            nvidia.com/gpu: 1
        command:
        - bash
        - -c
        - |
          export MASTER_ADDR=inference-test-0.inference-test-headless
          export MASTER_PORT=29500
          export WORLD_SIZE=2
          export RANK=$JOB_COMPLETION_INDEX
          echo "Master: $MASTER_ADDR"
          echo "Rank: $RANK"
          torchrun \
            --nnodes=2 \
            --nproc_per_node=1 \
            --rdzv_id=101 \
            --rdzv_backend=c10d \
            --rdzv_endpoint=$MASTER_ADDR:$MASTER_PORT \
            --node_rank=$RANK \
            --master_addr=$MASTER_ADDR \
            --master_port=$MASTER_PORT \
            src/main.py --model Qwen/Qwen2.5-7B-Instruct
      nodeSelector:
        cloud.google.com/gke-accelerator: nvidia-l4
      restartPolicy: Never
  backoffLimit: 0
